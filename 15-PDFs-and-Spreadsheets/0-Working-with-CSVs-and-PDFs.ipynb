{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "second-campaign",
   "metadata": {},
   "source": [
    "# Working with CSV Files\n",
    "\n",
    "Now we'll discuss how to work with CSV files in Python.\n",
    "\n",
    "A file with the `.csv` extension is a Comma Separated Values (CSV) file. All CSV files are :\n",
    "- plain text\n",
    "- contain alphanumeric characters, and\n",
    "- structure the data contained within them in a tabular form.\n",
    "\n",
    "**Don't confuse Excel Files with CSV files**, while csv files are formatted very similarly to excel files, they don't have data types for their values, they are all strings with no font or color. They also don't have worksheets the way an excel file does. Python does have several libraries to work with Excel files, you can check them out at http://www.python-excel.org/ and https://www.xlwings.org/.\n",
    "\n",
    "> Note that, while it's possible to export excel files and Goolge spreadsheets to .csv files. It **only** exports the raw information. Things ike macros, formulas, images can not be in a .csv file.<br>**Simply put, a csv file only contains the raw data from spreadhseet.**\n",
    "\n",
    "\n",
    "Files in the CSV format are generally used to exchange data, usually when there's a large amount, between different applications. Database programs, analytical software, and other applications that store massive amounts of information (like contacts and customer data), will usually support the CSV format.\n",
    "\n",
    "Let's explore how we can open a csv file with Python's built-in csv library.\n",
    "\n",
    "### Reading CSV files\n",
    "\n",
    "When passing in the file path, make sure to include the extension if it has one, you should be able to Tab Autocomplete the file name. If doing the Tab autocomplete doesn't show up anything, that's a good indicator your file isn't at the same location as your notebook. You can always type in the entire file path (it will look similar in formatting to the output of pwd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "integrated-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "canadian-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open csv file\n",
    "\n",
    "data = open('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mental-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='example.csv' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-strategy",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "Often, csv files may contain characters that you can't interpret with standard python, this could be something like an `@` symbol, or even foreign characters. Let's view an example of this sort of error (its pretty common, so it's important to go through).\n",
    "\n",
    "https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "experimental-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from csv file\n",
    "\n",
    "csvData = csv.reader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daily-recognition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x113fd97d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-choir",
   "metadata": {},
   "source": [
    "Now, casting _csvData_ to a list may give an error or may not even display nothing inspite that data is present in it. It could be because the encoding scheme of reading the csv file is not compliant.<br>See below example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "formal-williams",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLines = list(csvData)\n",
    "\n",
    "dataLines[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-fiber",
   "metadata": {},
   "source": [
    "**So try reading it with a \"utf-8\" encoding.**\n",
    "\n",
    "> **Tip:** You can simply search online for different encodings and pick up which enciding may suite your requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "seventh-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city'],\n",
       " ['1',\n",
       "  'Joseph',\n",
       "  'Zaniolini',\n",
       "  'jzaniolini0@simplemachines.org',\n",
       "  'Male',\n",
       "  '163.168.68.132',\n",
       "  'Pedro Leopoldo'],\n",
       " ['2',\n",
       "  'Freida',\n",
       "  'Drillingcourt',\n",
       "  'fdrillingcourt1@umich.edu',\n",
       "  'Female',\n",
       "  '97.212.102.79',\n",
       "  'Buri'],\n",
       " ['3',\n",
       "  'Nanni',\n",
       "  'Herity',\n",
       "  'nherity2@statcounter.com',\n",
       "  'Female',\n",
       "  '145.151.178.98',\n",
       "  'Claver']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open file\n",
    "data = open('example.csv', encoding=\"utf-8\")\n",
    "\n",
    "# Read csv data from file\n",
    "csvData = csv.reader(data)\n",
    "\n",
    "# convert data into a list\n",
    "dataLines = list(csvData)\n",
    "\n",
    "dataLines[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-poison",
   "metadata": {},
   "source": [
    "Cool, it worked! **Looks like, _dataLines_ is a list of lists.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "homeless-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-document",
   "metadata": {},
   "source": [
    "So, the first item in the list is the header line; this contains the column names i.e. the info about what each column represents.\n",
    "\n",
    "Let's format our printing just a bit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "configured-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city']\n",
      "['1', 'Joseph', 'Zaniolini', 'jzaniolini0@simplemachines.org', 'Male', '163.168.68.132', 'Pedro Leopoldo']\n",
      "['2', 'Freida', 'Drillingcourt', 'fdrillingcourt1@umich.edu', 'Female', '97.212.102.79', 'Buri']\n",
      "['3', 'Nanni', 'Herity', 'nherity2@statcounter.com', 'Female', '145.151.178.98', 'Claver']\n",
      "['4', 'Orazio', 'Frayling', 'ofrayling3@economist.com', 'Male', '25.199.143.143', 'Kungur']\n"
     ]
    }
   ],
   "source": [
    "for line in dataLines[:5]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-presentation",
   "metadata": {},
   "source": [
    "Let's imagine we wanted a list of all the emails. For demonstration, since there are 1000 items plus the header, we will only do a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "banner-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataLines)                # 1000 rows of data + 1 row for cloumn-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abandoned-cherry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jzaniolini0@simplemachines.org',\n",
       " 'fdrillingcourt1@umich.edu',\n",
       " 'nherity2@statcounter.com',\n",
       " 'ofrayling3@economist.com',\n",
       " 'jmurrison4@cbslocal.com',\n",
       " 'lgamet5@list-manage.com',\n",
       " 'dhowatt6@amazon.com',\n",
       " 'kherion7@amazon.com',\n",
       " 'chedworth8@china.com.cn',\n",
       " 'hgasquoine9@google.ru',\n",
       " 'ftarra@shareasale.com',\n",
       " 'abathb@umn.edu',\n",
       " 'lchastangc@goo.gl',\n",
       " 'cceried@yale.edu']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allEmails = []\n",
    "for line in dataLines[1:15]:\n",
    "    allEmails.append(line[3])\n",
    "    \n",
    "allEmails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-treasury",
   "metadata": {},
   "source": [
    "Similarly, let's we take out the list of full names :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aerial-target",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joseph Zaniolini',\n",
       " 'Freida Drillingcourt',\n",
       " 'Nanni Herity',\n",
       " 'Orazio Frayling',\n",
       " 'Julianne Murrison',\n",
       " 'Lucy Gamet',\n",
       " 'Dyana Howatt',\n",
       " 'Kassey Herion',\n",
       " 'Chrissy Hedworth',\n",
       " 'Hyatt Gasquoine',\n",
       " 'Felicdad Tarr',\n",
       " 'Andrew Bath',\n",
       " 'Lucais Chastang',\n",
       " 'Car Cerie']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullNames = []\n",
    "\n",
    "for line in dataLines[1:15]:\n",
    "    fullNames.append(line[1] + ' ' + line[2])\n",
    "\n",
    "fullNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "blessed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-locator",
   "metadata": {},
   "source": [
    "### Writing to CSV files\n",
    "\n",
    "We can also write csv files, either new ones or add on to existing ones.\n",
    "\n",
    "#### New File\n",
    "\n",
    "***This will also overwrite any exisiting file with the same name, so be careful with this !***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "convinced-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newline controls how universal newlines works (it only applies to text mode).\n",
    "# It can be None, '', '\\n', '\\r', and '\\r\\n'.\n",
    "\n",
    "file_to_output = open('to_save_file.csv', 'w', newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "violent-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvWriter = csv.writer(file_to_output, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-pride",
   "metadata": {},
   "source": [
    "Mostly, the delimiter is kept as comma `,` but some may keep it as `\\t` i.e. tabs (called as Tab-Seperated-Files), or a `;` i.e. a colon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ecological-spirituality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvWriter.writerow(['Name', 'Years of Expereince', 'Primary Skill'])\n",
    "\n",
    "\n",
    "# Remember, writing the first row in a csv file is always the cloumn-names like this line-of-code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "danish-accuracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvWriter.writerow(['Arpan', 3, 'Python'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "comprehensive-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why not write multiple rows or data-points just at once,\n",
    "\n",
    "csvWriter.writerows([['Arpan', 3, 'Machine Learning'], ['Deepak', 2, 'Blockchain'], ['Satyam', 4, 'Cloud computing'], ['Rajat', 2, 'NodeJS']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "intermediate-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-ceremony",
   "metadata": {},
   "source": [
    "**Remember,** to close the file after writing is done because you won't be able to read the file unless it's closed.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "living-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Name', 'Years of Expereince', 'Primary Skill'],\n",
       " ['Arpan', '3', 'Python'],\n",
       " ['Arpan', '3', 'Machine Learning'],\n",
       " ['Deepak', '2', 'Blockchain'],\n",
       " ['Satyam', '4', 'Cloud computing'],\n",
       " ['Rajat', '2', 'NodeJS']]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomRead = open('to_save_file.csv', encoding=\"utf-8\")\n",
    "\n",
    "csv_data = csv.reader(randomRead)\n",
    "\n",
    "lines = list(csv_data)\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-soccer",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### Existing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "protective-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "editFile = open('to_save_file.csv','a',newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "residential-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_writer = csv.writer(editFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "specific-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_writer.writerow(['Shubhi','3','C# VB-Script'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "quiet-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "editFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-maldives",
   "metadata": {},
   "source": [
    "<br>\n",
    "________________________________________________________________________________________________________________\n",
    "\n",
    "# Working with PDFs\n",
    "\n",
    "Often you will have to deal with PDF files. There are [many libraries in Python for working with PDFs](https://www.binpress.com/tutorial/manipulating-pdfs-with-python/167), each with their pros and cons, the most common one being **PyPDF2**. You can install it with (note the case-sensitivity, you need to make sure your capitilization matches) :\n",
    "\n",
    "`pip install PyPDF2`\n",
    "\n",
    "**Keep in mind that not every PDF file can be read with this library.**<br>PDFs that are too blurry, have a special encoding, encrypted, or maybe just created with a particular program that doesn't work well with PyPDF2 won't be able to be read. If you find yourself in this situation, try using the libraries linked above, but keep in mind, these may also not work. The reason for this is because of the many different parameters for a PDF and how non-standard the settings can be, text could be shown as an image instead of a utf-8 encoding. There are many parameters to consider in this aspect.\n",
    "\n",
    "As far as PyPDF2 is concerned, it can only read the text from a PDF document, it won't be able to grab images or other media files from a PDF.\n",
    "\n",
    "### Working with PyPDF2\n",
    "\n",
    "Let's being showing the basics of the PyPDF2 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "flying-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-moore",
   "metadata": {},
   "source": [
    "### Reading PDFs\n",
    "\n",
    "Similar to the `csv` library, we open a pdf, then create a reader object for it. Notice how we use the binary method of reading, `'rb'`, instead of just `'r'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fantastic-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we read it as a binary with 'rb'\n",
    "\n",
    "f = open('Working_Business_Proposal.pdf','rb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "brown-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = PyPDF2.PdfFileReader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "numerical-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to view number of pages in this PDF file, simply use .numPages attribute.\n",
    "\n",
    "pdf_reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "understanding-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pageOne = pdf_reader.getPage(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-compromise",
   "metadata": {},
   "source": [
    "We can then extract the text :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "endangered-madison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business Proposal\\n The Revolution is Coming\\n Leverage agile frameworks to provide a robust synopsis for high level \\noverviews. Iterative approaches to corporate strategy foster collaborative \\nthinking to further the overall value proposition. Organically grow the \\nholistic world view of disruptive innovation via workplace diversity and \\nempowerment. \\nBring to the table win-win survival strategies to ensure proactive \\ndomination. At the end of the day, going forward, a new normal that has \\nevolved from generation X is on the runway heading towards a streamlined \\ncloud solution. User generated content in real-time will have multiple \\ntouchpoints for offshoring. \\nCapitalize on low hanging fruit to identify a ballpark value added activity to \\nbeta test. Override the digital divide with additional clickthroughs from \\nDevOps. Nanotechnology immersion along the information highway will \\nclose the loop on focusing solely on the bottom line. Podcasting operational change management inside of workßows to \\nestablish a framework. Taking seamless key performance indicators ofßine \\nto maximise the long tail. Keeping your eye on the ball while performing a \\ndeep dive on the start-up mentality to derive convergence on cross-\\nplatform integration. \\nCollaboratively administrate empowered markets via plug-and-play \\nnetworks. Dynamically procrastinate B2C users after installed base \\nbeneÞts. Dramatically visualize customer directed convergence without \\nrevolutionary ROI. \\nEfÞciently unleash cross-media information without cross-media value. \\nQuickly maximize timely deliverables for real-time schemas. Dramatically \\nmaintain clicks-and-mortar solutions without functional solutions. \\nBUSINESS PROPOSAL\\n!1'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pageOne_text = pageOne.extractText()\n",
    "\n",
    "pageOne_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-forth",
   "metadata": {},
   "source": [
    "> If the `.extractText()` method returns an empty string, then it's evident that either the text in that particular page is either blurry, or is an image, etc. or is of different encoding or may be incompatible with PyPDF2 for conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "apart-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-undergraduate",
   "metadata": {},
   "source": [
    "### Adding to PDFs\n",
    "\n",
    "We can not write to PDFs using Python because of the differences between the single string type of Python, and the variety of fonts, placements, and other parameters that a PDF could have.\n",
    "\n",
    "What we can do is copy or append pages to the end of an existing PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "promotional-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Working_Business_Proposal.pdf','rb')\n",
    "\n",
    "pdf_reader = PyPDF2.PdfFileReader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "unique-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPage = pdf_reader.getPage(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "civilian-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyPDF2.pdf.PageObject"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(firstPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "continental-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_writer = PyPDF2.PdfFileWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-heart",
   "metadata": {},
   "source": [
    "A `.pdf.PageObject` object type can be added/written by the _pdf_writer_ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "robust-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_writer.addPage(firstPage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fossil-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_output = open(\"Some_New_Doc.pdf\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "recent-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_writer.write(pdf_output)\n",
    "\n",
    "f.close()\n",
    "pdf_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-regard",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "### _Simple Example - 1_\n",
    "\n",
    "Let's try to grab all the text from this PDF file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "colonial-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Working_Business_Proposal.pdf','rb')\n",
    "\n",
    "# List of every page's text.\n",
    "# The index will correspond to the page number.\n",
    "pdf_text = []\n",
    "\n",
    "pdf_reader = PyPDF2.PdfFileReader(f)\n",
    "\n",
    "for p in range(pdf_reader.numPages):\n",
    "    page = pdf_reader.getPage(p)\n",
    "    pdf_text.append(page.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "geological-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applications. Quickly drive clicks-and-mortar catalysts for change before \n",
      "vertical architectures. \n",
      "Credibly reintermediate backend ideas for cross-platform models. \n",
      "Continually reintermediate integrated processes through technically sound \n",
      "intellectual capital. Holistically foster superior methodologies without \n",
      "market-driven best practices. Distinctively exploit optimal alignments for intuitive bandwidth. Quickly \n",
      "coordinate e-business applications through revolutionary catalysts for \n",
      "change. Seamlessly underwhelm optimal testing procedures whereas \n",
      "bricks-and-clicks processes. \n",
      "Synergistically evolve 2.0 technologies rather than just in time initiatives. \n",
      "Quickly deploy strategic networks with compelling e-business. Credibly \n",
      "pontiÞcate highly efÞcient manufactured products and enabled data. \n",
      "Dynamically target high-payoff intellectual capital for customized \n",
      "technologies. Objectively integrate emerging core competencies before \n",
      "process-centric communities. Dramatically evisculate holistic innovation \n",
      "rather than client-centric data. Progressively maintain extensive infomediaries via extensible niches. \n",
      "Dramatically disseminate standardized metrics after resource-leveling \n",
      "processes. Objectively pursue diverse catalysts for change for \n",
      "interoperable meta-services. \n",
      "Proactively fabricate one-to-one materials via effective e-business. \n",
      "Completely synergize scalable e-commerce rather than high standards in \n",
      "e-services. Assertively iterate resource maximizing products after leading-\n",
      "edge intellectual capital. Distinctively re-engineer revolutionary meta-services and premium \n",
      "architectures. Intrinsically incubate intuitive opportunities and real-time \n",
      "potentialities. Appropriately communicate one-to-one technology after \n",
      "plug-and-play networks. Quickly aggregate B2B users and worldwide potentialities. Progressively \n",
      "plagiarize resource-leveling e-commerce through resource-leveling core \n",
      "BUSINESS PROPOSAL\n",
      "!3\n"
     ]
    }
   ],
   "source": [
    "# print the text on page-3\n",
    "\n",
    "print(pdf_text[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-generation",
   "metadata": {},
   "source": [
    "> Remember that this won't work with every PDF file and is limited in its scope to only text of PDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-judges",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "### _Simple Example - 2_\n",
    "\n",
    "Try to find a phone number, which is hidden, in the file Find_the_Phone_Number-exercise.pdf\n",
    "\n",
    "A good hint : https://stackoverflow.com/questions/4697882/how-can-i-find-all-matches-to-a-regular-expression-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "technological-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "f = open('Find_the_Phone_Number-exercise.pdf', 'rb')\n",
    "pdf = PyPDF2.PdfFileReader(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "composed-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.numPages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "experienced-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\d{3}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "appropriate-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "allText = ''\n",
    "\n",
    "for n in range(pdf.numPages):\n",
    "    page = pdf.getPage(n)\n",
    "    pageText = page.extractText()\n",
    "    allText = allText + ' ' + pageText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "tough-perfume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000', '000', '000', '505', '503', '445']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern, allText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dental-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(655, 658), match='000'>\n",
      "<re.Match object; span=(17805, 17808), match='000'>\n",
      "<re.Match object; span=(35059, 35062), match='000'>\n",
      "<re.Match object; span=(41808, 41811), match='505'>\n",
      "<re.Match object; span=(41812, 41815), match='503'>\n",
      "<re.Match object; span=(41816, 41819), match='445'>\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(pattern, allText):\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-alaska",
   "metadata": {},
   "source": [
    "So now with `.finditer()` method we have a clue of the index location of pattern in allText that begins with _505_.<br>We can do like,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "organic-boost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for me? His \\nphone number is 505.503.4455. So hor'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allText[41808-30:41808+20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-samba",
   "metadata": {},
   "source": [
    "**Great!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
